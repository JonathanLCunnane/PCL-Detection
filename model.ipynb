{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b568da",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "We will train various models:\n",
    "1. Raw DeBERTa-v3-base fine-tuning and large randomised hyperparameter search.\n",
    "2. DeBERTa-v3-base fine-tuning with POS and NER features and constrained hyperparameter grid search.\n",
    "3. DeBERTa-v3-base fine-tuning with z-scores from log-odds with Dirchlet prior features, ditto grid search.\n",
    "4. DeBERTa-v3-base fine-tuning with both of the above, ditto grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86330fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jlc/anaconda3/envs/mlenv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'Could not load this library: /home/jlc/anaconda3/envs/mlenv/lib/python3.10/site-packages/torchvision/image.so'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2026-02-13 12:16:15,705 INFO:\tDevice: cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import logging\n",
    "import math\n",
    "import json\n",
    "from html import unescape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "from transformers import DebertaV2Tokenizer, DebertaV2Model\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "from optuna.visualization.matplotlib import (\n",
    "    plot_optimization_history,\n",
    "    plot_param_importances,\n",
    "    plot_parallel_coordinate\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "SEED = 42\n",
    "DATA_DIR = \"data\"\n",
    "OUT_DIR = \"out\"\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "MAX_LENGTH = 256\n",
    "VAL_FRACTION = 0.15\n",
    "N_TRIALS = 30\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s:\\t%(message)s\")\n",
    "LOG = logging.getLogger(__name__)\n",
    "LOG.info(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6s4mqsts2",
   "metadata": {},
   "source": [
    "## 1. Data Loading and Preprocessing\n",
    "Load the main PCL dataset, join with the official SemEval train/dev splits, binarise labels, and clean HTML artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aecfbesa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 12:48:36,403 INFO:\tTrain: 8375 samples, 794 positive (9.48%)\n",
      "2026-02-13 12:48:36,417 INFO:\tDev:   2093 samples, 199 positive (9.51%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We 're living in times of absolute insanity , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In Libya today , there are countless number of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>White House press secretary Sean Spicer said t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Council customers only signs would be displaye...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\" Just like we received migrants fleeing El Sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  binary_label\n",
       "par_id                                                                 \n",
       "1       We 're living in times of absolute insanity , ...             0\n",
       "2       In Libya today , there are countless number of...             0\n",
       "3       White House press secretary Sean Spicer said t...             0\n",
       "4       Council customers only signs would be displaye...             0\n",
       "5       \" Just like we received migrants fleeing El Sa...             0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    \"\"\"Remove HTML noise, such as <h>/</h> tags, @@digits artifacts, and collapse whitespace.\"\"\"\n",
    "    text = unescape(text)\n",
    "    text = re.sub(r\"</?h>\", \"\", text)\n",
    "    text = re.sub(r\"@@\\d+\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def load_data(data_dir: str) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns (train_df, dev_df) each with columns: text, binary_label (0/1).\n",
    "    Index is par_id.\n",
    "    \"\"\"\n",
    "    col_names = [\"par_id\", \"art_id\", \"keyword\", \"country_code\", \"text\", \"label\"]\n",
    "    df = pd.read_csv(\n",
    "        os.path.join(data_dir, \"dontpatronizeme_pcl.tsv\"),\n",
    "        sep=\"\\t\", skiprows=4, names=col_names, index_col=\"par_id\"\n",
    "    )\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "    # Binarise: {0,1} -> 0, {2,3,4} -> 1\n",
    "    df[\"binary_label\"] = (df[\"label\"] >= 2).astype(int)\n",
    "\n",
    "    # Clean text\n",
    "    df[\"text\"] = df[\"text\"].apply(clean_text)\n",
    "\n",
    "    # Load official splits (par_id lists)\n",
    "    train_ids = pd.read_csv(os.path.join(data_dir, \"train_semeval_parids-labels.csv\"))[\"par_id\"].values\n",
    "    dev_ids = pd.read_csv(os.path.join(data_dir, \"dev_semeval_parids-labels.csv\"))[\"par_id\"].values\n",
    "\n",
    "    train_df = df.loc[df.index.isin(train_ids), [\"text\", \"binary_label\"]].copy()\n",
    "    dev_df = df.loc[df.index.isin(dev_ids), [\"text\", \"binary_label\"]].copy()\n",
    "\n",
    "    LOG.info(f\"Train: {len(train_df)} samples, {train_df['binary_label'].sum()} positive ({train_df['binary_label'].mean()*100:.2f}%)\")\n",
    "    LOG.info(f\"Dev:   {len(dev_df)} samples, {dev_df['binary_label'].sum()} positive ({dev_df['binary_label'].mean()*100:.2f}%)\")\n",
    "\n",
    "    return train_df, dev_df\n",
    "\n",
    "\n",
    "train_df, dev_df = load_data(DATA_DIR)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad407738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 12:16:32,660 INFO:\tTotal noise matches found: 0\n"
     ]
    }
   ],
   "source": [
    "for df in [train_df, dev_df]:\n",
    "    matches = 0\n",
    "    for row in df.itertuples():\n",
    "        para = str(row.text)\n",
    "        for match in re.finditer(r\"<[^>]+>|<\\/[^>]+>|&\\w+;|\\n|\\\\n|\\s{2,}|\\r|\\\\r|@@\\d+|[^\\x00-\\x7F]+|https?://\\S+\", para):\n",
    "            LOG.warning(f\"Found noise in par_id {row.Index}: '{match.group(0)}'\")\n",
    "            matches += 1\n",
    "LOG.info(f\"Total noise matches found: {matches}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "izzpky8r3y8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 12:48:55,477 INFO:\tTrain-sub: 7118 (675 pos, 9.48%), Val-sub: 1257 (119 pos, 9.47%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binary_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>par_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>The ruling by the judge , released Thursday , ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>News Rescuing the mentally ill CUMI provides h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6356</th>\n",
       "      <td>According to documents , the project will enab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>As a fashion icon , Rissa knows the importance...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6173</th>\n",
       "      <td>The new rules are not so much an outright ban ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  binary_label\n",
       "par_id                                                                 \n",
       "124     The ruling by the judge , released Thursday , ...             0\n",
       "1515    News Rescuing the mentally ill CUMI provides h...             1\n",
       "6356    According to documents , the project will enab...             0\n",
       "1008    As a fashion icon , Rissa knows the importance...             0\n",
       "6173    The new rules are not so much an outright ban ...             0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_train_val(train_df: pd.DataFrame, val_frac: float = VAL_FRACTION, seed: int = SEED):\n",
    "    \"\"\"\n",
    "    Stratified split of training data into train_sub and val_sub.\n",
    "    Returns (train_sub_df, val_sub_df).\n",
    "    \"\"\"\n",
    "    train_sub, val_sub = train_test_split(\n",
    "        train_df, test_size=val_frac, random_state=seed,\n",
    "        stratify=train_df[\"binary_label\"]\n",
    "    )\n",
    "    LOG.info(f\"Train-sub: {len(train_sub)} ({train_sub['binary_label'].sum()} pos, {train_sub['binary_label'].mean()*100:.2f}%), \"\n",
    "             f\"Val-sub: {len(val_sub)} ({val_sub['binary_label'].sum()} pos, {val_sub['binary_label'].mean()*100:.2f}%)\")\n",
    "    return train_sub, val_sub\n",
    "\n",
    "train_sub_df, val_sub_df = split_train_val(train_df)\n",
    "val_sub_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1moienrrv9",
   "metadata": {},
   "source": [
    "## 2. PyTorch Dataset and DataLoader\n",
    "Custom Dataset class that pre-tokenizes all texts with the DeBERTa tokeniser at construction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9quy4pyexvk",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-02-13 12:16:36,707 INFO:\tHTTP Request: HEAD https://huggingface.co/microsoft/deberta-v3-base/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
      "2026-02-13 12:16:36,722 INFO:\tHTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/microsoft/deberta-v3-base/8ccc9b6f36199bec6961081d44eb72fb3f7353f3/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
      "2026-02-13 12:16:36,832 INFO:\tHTTP Request: GET https://huggingface.co/api/models/microsoft/deberta-v3-base/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
      "2026-02-13 12:16:36,943 INFO:\tHTTP Request: GET https://huggingface.co/api/models/microsoft/deberta-v3-base/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
      "2026-02-13 12:16:43,075 INFO:\tHTTP Request: GET https://huggingface.co/api/models/microsoft/deberta-v3-base \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "tokenizer = DebertaV2Tokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "\n",
    "class PCLDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Pre-tokenising all of the text to prevent doing it each time it is needed.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts: list[str], labels: list[int] | None = None,\n",
    "                 max_length: int = MAX_LENGTH):\n",
    "        self.encodings = tokenizer(\n",
    "            texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=max_length,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32) if labels is not None else None\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx: int) -> dict:\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item[\"labels\"] = self.labels[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c33nqgjw0kc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloaders(\n",
    "    train_sub_df: pd.DataFrame,\n",
    "    val_sub_df: pd.DataFrame,\n",
    "    dev_df: pd.DataFrame,\n",
    "    batch_size: int\n",
    ") -> tuple[DataLoader, DataLoader, DataLoader]:\n",
    "    \"\"\"Create DataLoaders for train-sub, val-sub, and dev sets.\"\"\"\n",
    "    train_ds = PCLDataset(train_sub_df[\"text\"].tolist(), train_sub_df[\"binary_label\"].tolist())\n",
    "    val_ds = PCLDataset(val_sub_df[\"text\"].tolist(), val_sub_df[\"binary_label\"].tolist())\n",
    "    dev_ds = PCLDataset(dev_df[\"text\"].tolist(), dev_df[\"binary_label\"].tolist())\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_ds, batch_size=batch_size, shuffle=False)\n",
    "    dev_loader = DataLoader(dev_ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader, dev_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uyjt4f9znen",
   "metadata": {},
   "source": [
    "## 3. Model Architecture\n",
    "DeBERTa backbone + custom classifier head. The head is designed for future concatenation of extra features (POS/NER proportions, z-score features) but for Experiment 1 uses only the [CLS] embedding.\n",
    "\n",
    "**Classifier head design**: We use a two-layer MLP (Linear -> GELU -> Dropout -> Linear) rather than a single linear layer. A single linear layer can only learn a linear relationship but we want to be able to learn non-linear relationships (between transformer embeddings, POS/NER proportions, and z-scores). The hidden layer with GELU activation allows the head to learn nonlinear combinations of these features. GELU is chosen over ReLU because it is continuously differentiable and never has zero gradient, avoiding the dying neuron problem where ReLU. A deeper classification head might overfit given the small-ish dataset (~8k training samples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5wnz2mpthpd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCLClassifierHead(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom classifier head for PCL detection.\n",
    "\n",
    "    Architecture: Linear -> GELU -> Dropout -> Linear -> (raw output)\n",
    "\n",
    "    The first linear layer accepts (cls_dim + n_extra_features) as input,\n",
    "    allowing future experiments to concatenate additional features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cls_dim: int = 768, hidden_dim: int = 256,\n",
    "                 dropout_rate: float = 0.1, n_extra_features: int = 0):\n",
    "        super().__init__()\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(cls_dim + n_extra_features, hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim, 1), # Sigmoid applied with BCEWithLogitsLoss for numerical stability.\n",
    "        )\n",
    "\n",
    "    def forward(self, cls_embedding: torch.Tensor,\n",
    "                extra_features: torch.Tensor | None = None) -> torch.Tensor:\n",
    "        if extra_features is not None:\n",
    "            x = torch.cat([cls_embedding, extra_features], dim=-1)\n",
    "        else:\n",
    "            x = cls_embedding\n",
    "        return self.head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "me9lbp4sn9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCLDeBERTa(nn.Module):\n",
    "    \"\"\"\n",
    "    Full model: DeBERTa backbone + PCLClassifierHead.\n",
    "    Extracts the [CLS] token embedding from the last hidden state\n",
    "    and passes it through the classifier head.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hidden_dim: int = 256, dropout_rate: float = 0.1,\n",
    "                 n_extra_features: int = 0):\n",
    "        super().__init__()\n",
    "        self.backbone = DebertaV2Model.from_pretrained(MODEL_NAME)\n",
    "        cls_dim = self.backbone.config.hidden_size  # 768\n",
    "        self.classifier = PCLClassifierHead(\n",
    "            cls_dim=cls_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            dropout_rate=dropout_rate,\n",
    "            n_extra_features=n_extra_features\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor,\n",
    "                token_type_ids: torch.Tensor | None = None,\n",
    "                extra_features: torch.Tensor | None = None) -> torch.Tensor:\n",
    "        outputs = self.backbone(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids\n",
    "        )\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # (batch, 768)\n",
    "        scores = self.classifier(cls_embedding, extra_features)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45sv4r6w14m",
   "metadata": {},
   "source": [
    "## 4. Loss Function, Scheduler, and Training Infrastructure\n",
    "Weighted BCE loss for class imbalance, cosine annealing with warmup, early stopping, and evaluation utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6rwzhtstvkm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pos_weight(df: pd.DataFrame) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute pos_weight for BCEWithLogitsLoss to handle class imbalance.\n",
    "    pos_weight = num_negatives / num_positives, upweighting the minority class.\n",
    "    \"\"\"\n",
    "    n_pos = df[\"binary_label\"].sum()\n",
    "    n_neg = len(df) - n_pos\n",
    "    weight = torch.tensor([n_neg / n_pos], dtype=torch.float32).to(DEVICE)\n",
    "    LOG.info(f\"pos_weight = {weight.item():.2f} (neg={n_neg}, pos={n_pos})\")\n",
    "    return weight\n",
    "\n",
    "\n",
    "def get_cosine_schedule_with_warmup(\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    num_warmup_steps: int,\n",
    "    num_training_steps: int\n",
    ") -> LambdaLR:\n",
    "    \"\"\"\n",
    "    Cosine annealing LR schedule with linear warmup.\n",
    "    - step < num_warmup_steps: LR increases linearly from 0 to base_lr.\n",
    "    - step >= num_warmup_steps: LR decays following a cosine curve to 0.\n",
    "    \"\"\"\n",
    "    def lr_lambda(current_step: int) -> float:\n",
    "        if current_step < num_warmup_steps:\n",
    "            return float(current_step) / float(max(1, num_warmup_steps))\n",
    "        progress = float(current_step - num_warmup_steps) / float(max(1, num_training_steps - num_warmup_steps))\n",
    "        return max(0.0, 0.5 * (1.0 + math.cos(math.pi * progress)))\n",
    "\n",
    "    return LambdaLR(optimizer, lr_lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5k0q1mzlpn3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Early stopping based on validation F1 (higher is better).\n",
    "    Patience is in units of evaluation rounds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, patience: int = 3, min_delta: float = 0.0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score: float | None = None\n",
    "        self.should_stop = False\n",
    "\n",
    "    def step(self, val_f1: float) -> bool:\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_f1\n",
    "        elif val_f1 > self.best_score + self.min_delta:\n",
    "            self.best_score = val_f1\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.should_stop = True\n",
    "        return self.should_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bqu9jobre8j",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model: nn.Module, dataloader: DataLoader, threshold: float = 0.5) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluate the model on a DataLoader.\n",
    "    Returns dict with keys: f1, precision, recall, loss, preds, labels.\n",
    "    \"\"\"\n",
    "    was_training = model.training\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        labels = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "        unnormalised_scores = model(input_ids=input_ids, attention_mask=attention_mask).squeeze(-1)\n",
    "        all_scores.append(unnormalised_scores.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "    all_scores = torch.cat(all_scores)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "\n",
    "    loss = nn.functional.binary_cross_entropy_with_logits(all_scores, all_labels).item()\n",
    "\n",
    "    probs = torch.sigmoid(all_scores)\n",
    "    thresh_preds = (probs >= threshold).long().numpy()\n",
    "    labels_np = all_labels.long().numpy()\n",
    "\n",
    "    f1 = f1_score(labels_np, thresh_preds, zero_division=0)\n",
    "    precision = precision_score(labels_np, thresh_preds, zero_division=0)\n",
    "    recall = recall_score(labels_np, thresh_preds, zero_division=0)\n",
    "\n",
    "    model.train(was_training)\n",
    "    return {\n",
    "        \"f1\": f1, \"precision\": precision, \"recall\": recall,\n",
    "        \"loss\": loss, \"preds\": thresh_preds, \"labels\": labels_np\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zhqoezmqvip",
   "metadata": {},
   "source": [
    "## 5. Training Loop\n",
    "Single training function used both for manual runs and as the Optuna objective. Uses differential learning rates (backbone vs head), gradient clipping, step-based evaluation, and Optuna pruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uao1a5n7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model: PCLDeBERTa,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    dev_loader: DataLoader,\n",
    "    pos_weight: torch.Tensor,\n",
    "    lr: float,\n",
    "    weight_decay: float,\n",
    "    num_epochs: int,\n",
    "    warmup_fraction: float,\n",
    "    patience: int,\n",
    "    eval_every_n_steps: int = 50,\n",
    "    trial: optuna.trial.Trial | None = None\n",
    ") -> dict:\n",
    "    \"\"\"\n",
    "    Train the model with early stopping, cosine annealing with warmup,\n",
    "    and weighted BCE loss.\n",
    "\n",
    "    Returns dict with keys: best_val_f1, dev_metrics, train_losses.\n",
    "    \"\"\"\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "    # Differential LR: head learns 10x faster than backbone\n",
    "    backbone_params = list(model.backbone.parameters())\n",
    "    head_params = list(model.classifier.parameters())\n",
    "    optimizer = AdamW([\n",
    "        {\"params\": backbone_params, \"lr\": lr},\n",
    "        {\"params\": head_params, \"lr\": lr * 10}\n",
    "    ], weight_decay=weight_decay)\n",
    "\n",
    "    total_steps = len(train_loader) * num_epochs\n",
    "    warmup_steps = int(total_steps * warmup_fraction)\n",
    "    scheduler = get_cosine_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
    "\n",
    "    early_stopper = EarlyStopping(patience=patience)\n",
    "\n",
    "    model.train()\n",
    "    global_step = 0\n",
    "    train_losses = []\n",
    "    best_val_f1 = 0.0\n",
    "    best_state_dict = None\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "            attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "            labels = batch[\"labels\"].to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            unnormalised_scores = model(input_ids=input_ids, attention_mask=attention_mask).squeeze(-1)\n",
    "            loss = criterion(unnormalised_scores, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            if global_step % eval_every_n_steps == 0:\n",
    "                val_metrics = evaluate(model, val_loader)\n",
    "                val_f1 = val_metrics[\"f1\"]\n",
    "                train_losses.append(running_loss / eval_every_n_steps)\n",
    "                running_loss = 0.0\n",
    "\n",
    "                LOG.info(\n",
    "                    f\"Step {global_step} | Val F1: {val_f1:.4f} | \"\n",
    "                    f\"Val P: {val_metrics['precision']:.4f} | Val R: {val_metrics['recall']:.4f}\"\n",
    "                )\n",
    "\n",
    "                if val_f1 > best_val_f1:\n",
    "                    best_val_f1 = val_f1\n",
    "                    best_state_dict = {k: v.clone() for k, v in model.state_dict().items()}\n",
    "\n",
    "                # Optuna pruning\n",
    "                if trial is not None:\n",
    "                    trial.report(val_f1, global_step)\n",
    "                    if trial.should_prune():\n",
    "                        raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "                if early_stopper.step(val_f1):\n",
    "                    LOG.info(f\"Early stopping at step {global_step}\")\n",
    "                    break\n",
    "\n",
    "        if early_stopper.should_stop:\n",
    "            break\n",
    "\n",
    "    # Restore best model and evaluate on dev set\n",
    "    if best_state_dict is not None:\n",
    "        model.load_state_dict(best_state_dict)\n",
    "\n",
    "    dev_metrics = evaluate(model, dev_loader)\n",
    "    LOG.info(\n",
    "        f\"Dev F1: {dev_metrics['f1']:.4f} | \"\n",
    "        f\"Dev P: {dev_metrics['precision']:.4f} | Dev R: {dev_metrics['recall']:.4f}\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"best_val_f1\": best_val_f1,\n",
    "        \"dev_metrics\": dev_metrics,\n",
    "        \"train_losses\": train_losses\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ph68mkbge0g",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Search with Optuna\n",
    "Randomised search over learning rate, batch size, hidden dim, dropout, weight decay, warmup fraction, and number of epochs. The objective is dev-set F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632jyvedb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial: optuna.trial.Trial) -> float:\n",
    "    \"\"\"\n",
    "    Optuna objective for Experiment 1.\n",
    "    Returns dev-set F1 score (to be maximised).\n",
    "    \"\"\"\n",
    "    lr = trial.suggest_float(\"lr\", 5e-6, 5e-5, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [16, 32])\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [128, 256, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5, step=0.05)\n",
    "    weight_decay = trial.suggest_float(\"weight_decay\", 1e-4, 1e-1, log=True)\n",
    "    warmup_fraction = trial.suggest_float(\"warmup_fraction\", 0.0, 0.2, step=0.05)\n",
    "    num_epochs = trial.suggest_int(\"num_epochs\", 3, 8)\n",
    "    patience = trial.suggest_int(\"patience\", 3, 6)\n",
    "\n",
    "    train_loader, val_loader, dev_loader = make_dataloaders(\n",
    "        train_sub_df, val_sub_df, dev_df, batch_size\n",
    "    )\n",
    "\n",
    "    model = PCLDeBERTa(\n",
    "        hidden_dim=hidden_dim,\n",
    "        dropout_rate=dropout_rate,\n",
    "        n_extra_features=0\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    pos_weight = compute_pos_weight(train_sub_df)\n",
    "\n",
    "    results = train_model(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        dev_loader=dev_loader,\n",
    "        pos_weight=pos_weight,\n",
    "        lr=lr,\n",
    "        weight_decay=weight_decay,\n",
    "        num_epochs=num_epochs,\n",
    "        warmup_fraction=warmup_fraction,\n",
    "        patience=patience,\n",
    "        eval_every_n_steps=50,\n",
    "        trial=trial\n",
    "    )\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return results[\"dev_metrics\"][\"f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ni3zwmxv7",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(\n",
    "    direction=\"maximize\",\n",
    "    study_name=\"pcl_deberta_exp1\",\n",
    "    pruner=optuna.pruners.MedianPruner(n_startup_trials=5, n_warmup_steps=100)\n",
    ")\n",
    "\n",
    "study.optimize(objective, n_trials=N_TRIALS)\n",
    "\n",
    "logger.info(f\"Best trial: {study.best_trial.number}\")\n",
    "logger.info(f\"Best dev F1: {study.best_trial.value:.4f}\")\n",
    "logger.info(f\"Best params: {study.best_trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278hf962yv",
   "metadata": {},
   "source": [
    "## 7. Results Analysis\n",
    "Visualise Optuna results and retrain the best model on the full training set for final evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enyo3cowtta",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plot_optimization_history(study)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUT_DIR}/optuna_history.png\", dpi=300)\n",
    "plt.savefig(f\"{OUT_DIR}/optuna_history.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "fig2 = plot_param_importances(study)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUT_DIR}/optuna_importances.png\", dpi=300)\n",
    "plt.savefig(f\"{OUT_DIR}/optuna_importances.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "fig3 = plot_parallel_coordinate(study)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{OUT_DIR}/optuna_parallel.png\", dpi=300)\n",
    "plt.savefig(f\"{OUT_DIR}/optuna_parallel.svg\", format=\"svg\")\n",
    "plt.show()\n",
    "\n",
    "best_params = study.best_trial.params\n",
    "print(\"Best hyperparameters for Experiment 1:\")\n",
    "for k, v in best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saxpej92j9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain with best HPs on full training set (no val carve-out)\n",
    "best = study.best_trial.params\n",
    "\n",
    "full_train_ds = PCLDataset(train_df[\"text\"].tolist(), train_df[\"binary_label\"].tolist())\n",
    "full_train_loader = DataLoader(full_train_ds, batch_size=best[\"batch_size\"], shuffle=True)\n",
    "dev_ds = PCLDataset(dev_df[\"text\"].tolist(), dev_df[\"binary_label\"].tolist())\n",
    "dev_loader = DataLoader(dev_ds, batch_size=best[\"batch_size\"], shuffle=False)\n",
    "\n",
    "final_model = PCLDeBERTa(\n",
    "    hidden_dim=best[\"hidden_dim\"],\n",
    "    dropout_rate=best[\"dropout_rate\"],\n",
    "    n_extra_features=0\n",
    ").to(DEVICE)\n",
    "\n",
    "pos_weight = compute_pos_weight(train_df)\n",
    "\n",
    "final_results = train_model(\n",
    "    model=final_model,\n",
    "    train_loader=full_train_loader,\n",
    "    val_loader=dev_loader,\n",
    "    dev_loader=dev_loader,\n",
    "    pos_weight=pos_weight,\n",
    "    lr=best[\"lr\"],\n",
    "    weight_decay=best[\"weight_decay\"],\n",
    "    num_epochs=best[\"num_epochs\"],\n",
    "    warmup_fraction=best[\"warmup_fraction\"],\n",
    "    patience=best[\"patience\"],\n",
    "    eval_every_n_steps=50,\n",
    "    trial=None\n",
    ")\n",
    "\n",
    "print(\"\\nFinal Dev Set Classification Report:\")\n",
    "print(classification_report(\n",
    "    final_results[\"dev_metrics\"][\"labels\"],\n",
    "    final_results[\"dev_metrics\"][\"preds\"],\n",
    "    target_names=[\"Non-PCL\", \"PCL\"]\n",
    "))\n",
    "\n",
    "# Save model and best params for experiments 2-4\n",
    "torch.save(final_model.state_dict(), os.path.join(OUT_DIR, \"exp1_best_model.pt\"))\n",
    "with open(os.path.join(OUT_DIR, \"exp1_best_params.json\"), \"w\") as f:\n",
    "    json.dump(best, f, indent=2)\n",
    "logger.info(f\"Saved model to {OUT_DIR}/exp1_best_model.pt and params to {OUT_DIR}/exp1_best_params.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
